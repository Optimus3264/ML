# -*- coding: utf-8 -*-
"""Bagging /Cross validation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pUrnNVKQgAqDfXbJCE8UJn8WrU-GQwiT
"""

#1.Cross validation

import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import cross_val_score

df=pd.read_csv('ertiga_petrol_distance_data.csv')

x=df[['petrol_litres']]
y=df['distance_traveled_km']


# Linear Regression model
reg_model = LinearRegression()

# 5-fold cross-validation
cv_scores = cross_val_score(reg_model, x, y, cv=10)

print("Cross-validation scores:", cv_scores)
print("Average CV score:", cv_scores.mean())

#axis 0=column wise(down),axis 1=row wise(across).
#dependent column =distance travelled should be on axis 0.
#Cross-validation helps estimate how well the model will perform on unseen data. Instead of relying on a single train-test split (which might be biased), it averages performance over multiple splits.
#accuracy increases as per no of cv-folds increase.

#2.Bootstrap Aggregation/Bagging

#Data preparation
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.ensemble import BaggingRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt
from scipy.stats import entropy
import seaborn as sns

# Load data
data = pd.read_csv('ertiga_petrol_distance_data.csv')
X = data[['petrol_litres']]
y = data['distance_traveled_km']

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#BAGGING

# Create base estimator
base_estimator = DecisionTreeRegressor(random_state=42)

# Create bagging regressor
bagging = BaggingRegressor(estimator=base_estimator, n_estimators=100, random_state=42)

# Fit the model
bagging.fit(X_train, y_train)

# Evaluate
train_pred = bagging.predict(X_train)
test_pred = bagging.predict(X_test)

print(f"Bagging - Train MSE: {mean_squared_error(y_train, train_pred):.2f}")
print(f"Bagging - Test MSE: {mean_squared_error(y_test, test_pred):.2f}")

# Plot actual vs predicted
plt.figure(figsize=(10, 6))
plt.scatter(X_test, y_test, color='blue', label='Actual')
plt.scatter(X_test, test_pred, color='red', label='Predicted')
plt.xlabel('Petrol (Litres)')
plt.ylabel('Distance Traveled (km)')
plt.title('Bagging: Actual vs Predicted Distance')
plt.legend()
plt.show()

# prompt: plot cv score and average cv score

# Plotting the cross-validation scores
plt.figure(figsize=(8, 5))
plt.plot(range(1, len(cv_scores) + 1), cv_scores, marker='o', linestyle='-', color='skyblue', label='Individual CV Scores')
plt.axhline(y=cv_scores.mean(), color='red', linestyle='--', label=f'Average CV Score ({cv_scores.mean():.2f})')
plt.title('Cross-Validation Scores for Linear Regression')
plt.xlabel('Fold Number')
plt.ylabel('Score')
plt.xticks(range(1, len(cv_scores) + 1))
plt.legend()
plt.grid(True)
plt.show()

# prompt: plot cv score and average cv score

# Plotting the cross-validation scores
plt.figure(figsize=(8, 5))
plt.plot(range(1, len(cv_scores) + 1), cv_scores, marker='o', linestyle='-', color='skyblue', label='Individual CV Scores')
plt.axhline(y=cv_scores.mean(), color='red', linestyle='--', label=f'Average CV Score ({cv_scores.mean():.2f})')
plt.title('Cross-Validation Scores for Linear Regression')
plt.xlabel('Fold Number')
plt.ylabel('Score')
plt.xticks(range(1, len(cv_scores) + 1))
plt.legend()
plt.grid(True)
plt.show()