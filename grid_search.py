# -*- coding: utf-8 -*-
"""Grid_search

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1unIYfvq9ThdnVncglMCEFyHHmaPaoVHw
"""

from sklearn import datasets
from sklearn.linear_model import LogisticRegression

iris= datasets.load_iris()

x=iris['data']
y=iris['target']

logit= LogisticRegression(max_iter=10000)

C=[0.25,0.5,0.75,1,1.25,1.5,1.75,2]

scores=[]

for Choice in C:
  logit.set_params(C=Choice)
  logit.fit(x,y)
  scores.append(logit.score(x,y))

print(scores)
#You're trying to find which value of C gives the best performance for a Logistic Regression model.
#X contains the flower measurements (features).
#y contains the flower types (target labels).

import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
#from sklearn.metrics import accuracy_score

df=pd.read_csv('iris.csv')

x=df.drop('species', axis=1) # assuming 'sepcies' is the label column
y=df['species']

x_train, x_test, y_train, y_test= train_test_split(x,y,test_size=0.2, random_state=42)

#C_values = [0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2]
#scores=[]

#for c in C_values:
  #model=LogisticRegression(C=c, max_iter=10000)
  #model_fit=model.fit(x_train, y_train)
  #y_pred=model_fit.predict(x_test)
  #acc=accuracy_score(y_test, y_pred)
  #scores.append(acc)

  #print(f'C={c} -> Test Accuracy= {acc: .4f}')

logit = LogisticRegression(max_iter=10000)

param_grid = {'C': [0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2]}

grid_search = GridSearchCV(logit, param_grid, cv=5)
grid_search.fit(x_train, y_train)

print('Best Parameters:' , grid_search.best_params_)
print('Best Cross-Validation Accuracy:', grid_search.best_score_)
print('Test Accuracy on Holdolut Set:', grid_search.score(x_test, y_test))